{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c84bb9d-11d0-4c21-bc9f-4fd26a0b249f",
   "metadata": {},
   "source": [
    "**Q1**. What is the relationship between polynomial functions and kernel functions in machine learning\n",
    "algorithms?\n",
    "\n",
    "**Answer**:\n",
    "Polynomial functions and kernel functions are both commonly used in machine learning algorithms, particularly in the context of support vector machines (SVMs) and kernel methods.\n",
    "\n",
    "Polynomial functions are a type of function that involves powers of a variable raised to non-negative integer exponents. In the context of machine learning, polynomial functions can be used as a basis for feature transformation, where the original input features are transformed into higher-dimensional feature space using polynomial terms. This allows the learning algorithm to capture non-linear relationships between the features.\n",
    "\n",
    "Kernel functions, on the other hand, are a general concept in machine learning that define the similarity or distance measure between pairs of data points in a given feature space. In the context of SVMs and kernel methods, kernel functions are used to implicitly map the input data into a higher-dimensional feature space without explicitly calculating the transformed features. This is known as the \"kernel trick,\" which avoids the computational expense of explicitly transforming the data.\n",
    "\n",
    "Polynomial kernel functions are a specific type of kernel function that uses polynomial functions to define the similarity between data points. The polynomial kernel computes the similarity as the inner product between the original feature vectors raised to a certain power, which effectively captures polynomial relationships between the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f528b6-5236-4df7-a7cc-72a74a2f6e73",
   "metadata": {},
   "source": [
    "**Q2**. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n",
    "\n",
    "**Answer**:\n",
    "To implement an SVM with a polynomial kernel in Python using Scikit-learn, you can follow these steps:\n",
    "\n",
    "Step 1: Import the necessary libraries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9e4c0d-9033-4930-a1fb-a60974bbcf6f",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133cdd0b-8a3b-48a5-b2f8-4ba2f501602b",
   "metadata": {},
   "source": [
    "Step 2: Prepare your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e183cfa0-1b85-4c1d-a303-815de2af73ca",
   "metadata": {},
   "source": [
    " Assuming you have your features stored in X and labels in y\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbd8ddf-c360-4a26-b24b-e1b7d30b77a4",
   "metadata": {},
   "source": [
    "Step 3: Create an SVM classifier with a polynomial kernel\n",
    "\n",
    "svm_classifier = SVC(kernel='poly', degree=3)\n",
    "\n",
    "In the code above, the kernel='poly' parameter specifies that we want to use a polynomial kernel, and degree=3 specifies the degree of the polynomial.\n",
    "\n",
    "Step 4: Train the SVM classifier\n",
    "\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "Step 5: Make predictions\n",
    "\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "Step 6: Evaluate the performance\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fad786d-e9ed-4982-9e8c-e3be27b9a990",
   "metadata": {},
   "source": [
    "**Q3**. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
    "\n",
    "**Answer**:\n",
    "In Support Vector Regression (SVR), the value of epsilon determines the width of the epsilon-insensitive tube. This tube defines a range within which errors are considered acceptable and do not contribute to the loss function. Any data points falling within this tube are not treated as support vectors.\n",
    "\n",
    "When the value of epsilon is increased, the width of the epsilon-insensitive tube also increases. This means that a larger range of errors is considered acceptable, allowing more data points to fall within the tube without being treated as support vectors.\n",
    "\n",
    "Consequently, increasing the value of epsilon generally leads to a decrease in the number of support vectors in SVR. This is because a wider tube allows more data points to have a margin of error and not contribute significantly to the model's training process. As a result, the SVR model becomes less sensitive to individual data points, and fewer support vectors are needed to define the regression function.\n",
    "\n",
    "It's important to note that the effect of epsilon on the number of support vectors can vary depending on the specific dataset and problem at hand. In some cases, increasing epsilon may result in a substantial reduction in the number of support vectors, while in other cases, the impact may be minimal. Therefore, it's recommended to experiment with different values of epsilon and evaluate their effects on both the model's performance and the number of support vectors to find an appropriate balance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3c7759-d6f1-44a2-8158-a1c8268e08c2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "**Q4**. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
    "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
    "and provide examples of when you might want to increase or decrease its value?\n",
    "\n",
    "**Answer**:\n",
    "The performance of Support Vector Regression (SVR) is influenced by several key parameters: the choice of kernel function, C parameter, epsilon parameter, and gamma parameter. Let's discuss each parameter and how it affects SVR's performance:\n",
    "\n",
    "**Kernel Function:**\n",
    "SVR uses kernel functions to map the input data into a higher-dimensional feature space, where linear regression is performed. Common kernel functions include linear, polynomial, radial basis function (RBF), and sigmoid.\n",
    "The choice of the kernel function depends on the nature of the data and the problem at hand. For example:\n",
    "Linear kernel is useful when the relationship between features and the target variable is approximately linear.\n",
    "Polynomial kernel can capture non-linear relationships if the data exhibits polynomial patterns.\n",
    "RBF kernel is suitable for capturing complex non-linear relationships and is often a good default choice.\n",
    "Sigmoid kernel can be useful for problems with binary classification.\n",
    "\n",
    "**C Parameter:**\n",
    "The C parameter controls the trade-off between the flatness of the regression line and the amount of error tolerated.\n",
    "A smaller C value allows more errors (violations of the epsilon tube) during training, resulting in a wider margin and potentially more support vectors.\n",
    "A larger C value enforces a stricter tolerance for errors, leading to a narrower margin and potentially fewer support vectors.\n",
    "Increase C when you want to penalize errors more heavily and desire a more precise fit, but be cautious of overfitting.\n",
    "\n",
    "**Epsilon Parameter:**\n",
    "The epsilon parameter defines the width of the epsilon-insensitive tube in SVR. Data points falling within this tube do not contribute to the loss function.\n",
    "A larger epsilon value allows a wider range of errors to be considered acceptable, resulting in a larger tube and potentially fewer support vectors.\n",
    "A smaller epsilon value restricts the acceptable range of errors, leading to a narrower tube and potentially more support vectors.\n",
    "Increase epsilon when you want to allow more tolerance for errors and increase the size of the tube.\n",
    "\n",
    "**Gamma Parameter:**\n",
    "The gamma parameter defines the influence of each training example. It determines the reach of the individual training examples in the feature space.\n",
    "A smaller gamma value implies a broader influence, causing the SVR model to consider a wider range of examples when determining the regression function. This can result in a smoother and more generalized fit.\n",
    "A larger gamma value narrows the influence, causing the SVR model to focus more on closer training examples. This can lead to a more localized and wiggly fit.\n",
    "Increase gamma when you want to make the model more sensitive to nearby data points, especially in cases with high-dimensional datasets or when the target function varies rapidly.\n",
    "\n",
    "It's important to note that the optimal values for these parameters depend on the specific dataset and problem. It is recommended to experiment with different parameter values, perform cross-validation, and evaluate the model's performance metrics (e.g., mean squared error, R-squared) to find the best combination of parameters for your SVR model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092dfcaf-e8ff-4e35-ae6b-4963b47e989c",
   "metadata": {},
   "source": [
    "**Q5**. Assignment:\n",
    " Import the necessary libraries and load the datase\n",
    "\n",
    "Split the dataset into training and testing sets\n",
    "\n",
    "Preprocess the data using any technique of your choice (e.g. scaling,normailzation)\n",
    "\n",
    "Create an instance of the SVC classifier and train it on the training data\n",
    "\n",
    "hse the trained classifier to predict the labels of the testing data\n",
    "\n",
    "Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "\n",
    "precision, recall, F1-scoreK\n",
    "\n",
    "Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
    "improve its performanc_\n",
    "\n",
    "Train the tuned classifier on the entire dataseg\n",
    "\n",
    "Save the trained classifier to a file for future use.\n",
    "\n",
    "You can use any dataset of your choice for this assignment, but make sure it is suitable for\n",
    "classification and has a sufficient number of features and samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef64496-41d0-46a4-b653-abdcbfd29ff3",
   "metadata": {},
   "source": [
    "# Answer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46910d41-a886-497f-ab0a-4d0167401d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Import the necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Step 3: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20fbea74-469f-4d49-af6c-2f08a7474bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Preprocess the data (scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a3e4892-fdbb-44c0-a061-27ae6a26ae6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Create an instance of the SVC classifier and train it on the training data\n",
    "svc_classifier = SVC()\n",
    "svc_classifier.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76b122b6-f1ea-4c2b-a8ac-17f5b86e3a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Use the trained classifier to predict the labels of the testing data\n",
    "y_pred = svc_classifier.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the performance of the classifier (accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af6d4b24-3954-4915-9752-896a55664482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'gamma': 0.1, 'kernel': 'linear'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, gamma=0.1, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, gamma=0.1, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, gamma=0.1, kernel='linear')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 8: Tune the hyperparameters of the SVC classifier using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Step 9: Train the tuned classifier on the entire dataset\n",
    "svc_classifier_tuned = SVC(C=grid_search.best_params_['C'], gamma=grid_search.best_params_['gamma'], kernel=grid_search.best_params_['kernel'])\n",
    "svc_classifier_tuned.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ceeefe0-0c8f-4ef0-99d2-ab537a8ff3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svc_classifier_tuned.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 10: Save the trained classifier to a file for future use\n",
    "joblib.dump(svc_classifier_tuned, 'svc_classifier_tuned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc3417-eaf6-4987-95f4-56347fa2278e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
